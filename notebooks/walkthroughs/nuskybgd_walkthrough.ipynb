{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b1d1f7-b5c2-46c3-9323-67d0fe794461",
   "metadata": {},
   "source": [
    "# Walkthrough for nuskybgd-py\n",
    "\n",
    "Updated: 2021/09/21\n",
    "By: BG (bwgref@srl.caltech.edu)\n",
    "\n",
    "### Pre-requisites\n",
    "\n",
    "1. Install HEASoft\n",
    "2. Install pyXspec\n",
    "3. Install nuskybgd-py\n",
    "4. Download your data\n",
    "5. Process observation using ```nupipeline``` (standard processing through Stage 2)\n",
    "6. For simplicity, work in the SEQID/event_cl subdirectory. \n",
    "7. Make an event_cl/bgd directory\n",
    "\n",
    "Note that the example here is for N132D, a dataset that I've used ```nuskybgd``` on fairly extensively. This is sequence ID 10601407002."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a632e-fbf1-4797-98b5-b80b94decb67",
   "metadata": {},
   "source": [
    "# Define source and background background regions\n",
    "\n",
    "1. Make an image using nuproducts and/or using ds9 over the 3--20 keV bandpass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94b473-2fc3-4af4-90fe-d2fdad8835f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import nustar_gen as nsg\n",
    "from nustar_gen import info\n",
    "from nustar_gen import wrappers\n",
    "reload(wrappers)\n",
    "import os\n",
    "here = os.getcwd()+'/'\n",
    "\n",
    "import subprocess\n",
    "from subprocess import DEVNULL, STDOUT\n",
    "\n",
    "\n",
    "# Required to run heasoft stuff in the background\n",
    "%env HEADASNOQUERY=\n",
    "%env HEADASPROMPT=/dev/null\n",
    "\n",
    "\n",
    "obs = info.Observation(path=here, seqid='10601407002')\n",
    "obs.evtfiles['A'][0]\n",
    "obs.exposure_report()\n",
    "print(obs.observation_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb17e4-34a6-467a-9c96-9f2b6ab101d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a 3--20 keV image and a 20--40 keV image for both FPMs\n",
    "print(f'Output images are produced here here: {obs.out_path}')\n",
    "\n",
    "for mod in ['A', 'B']: \n",
    "    wrappers.make_image(infile=obs.evtfiles[mod][0], elow=3, ehigh=20)\n",
    "    wrappers.make_image(infile=obs.evtfiles[mod][0], elow=20, ehigh = 40)\n",
    "    \n",
    "# Set up an outdir\n",
    "outdir = os.path.join(obs.evdir, 'bgd')\n",
    "print(outdir)\n",
    "# Make the directory if it doesn't already exist\n",
    "try:\n",
    "    os.path.isdir(outdir)\n",
    "except:\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ed4e7-99fd-4ce5-b460-afd98ad9f0eb",
   "metadata": {},
   "source": [
    "# Define background regions, cont'd\n",
    "\n",
    "\n",
    "1. Try to generate regions *per detector*. Otherwise you are mixing instrument responses (and that can be bad or hard to diagnose later). Put these region files in the ```outdir``` that you specified above.\n",
    "\n",
    "![](./bgd_regions.pdf)\n",
    "\n",
    "\n",
    "2. Avoid any stray light regions when defining your backgrounds.\n",
    "4. As a sanity check, if you are near any bright X-ray binaries, make a 20--40 keV image as well and look for any signs of transmitted stray light (I did not do that here)\n",
    "5. Save the *individual* region files (not everything in one) into the bgd directory. Here I called my regions ```bgdA0.reg```, ```bgdA1.reg```, and ```bgdA3.reg``` since they were on detectors 0, 1 and 3. Do the same for FPMB.\n",
    "6. Use nuproducts to generate a spectrum for each of these background regions\n",
    "    * Note: The easiest way to do this is to use the “make_spectrum” wrapper in nustar-gen-utils, illustrated below.\n",
    "7. You'll probably want a full ```nuproducts``` run for the source spectrum. The ```wrapper.make_spectra``` below will work fine (just turn the runmkarf= parameter on), but editing your own script for extended source / etc, lightcurves is up to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d883b-d03f-43c6-a381-b2f3e6c3126c",
   "metadata": {},
   "source": [
    "# Generate a spectrum for each of your background regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be7f797-2ea8-4542-98fb-57f8170c8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the subprocess.run line bel to run this directly in the notebook\n",
    "# This can take a little while, so go run these shell scripts in the terminal\n",
    "\n",
    "bgd_regions = {'A':[0, 1, 3], 'B':[0, 1, 2, 3]}\n",
    "for mod in bgd_regions:\n",
    "    ev = obs.evtfiles[mod][0]\n",
    "    for reg in bgd_regions[mod]:\n",
    "        reg_file = os.path.join(outdir, f'bgd{reg}{mod}.reg')        \n",
    "        outscr = nsg.wrappers.make_spectra(ev, mod,reg_file,\n",
    "                                  runmkarf='no',\n",
    "                                  outpath=outdir)\n",
    "        print(outscr)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae9646-d72f-41e3-9569-84674f151e09",
   "metadata": {},
   "source": [
    "# You could have just followed the nuskybgd readme file, but it uses some other calls that aren't as flexible.\n",
    "\n",
    "For now, go to Step 3 in [the nuskybgd readme file](https://github.com/achronal/nuskybgd-py). I'll reproduce that here:\n",
    "\n",
    "1. Go to the event_cl directory in a terminal window\n",
    "2. Initialize the nuskybgd setup\n",
    "3. Make the instrument maps\n",
    "\n",
    "```\n",
    "nuskybgd mkinstrmap nu10601407002A01_cl.evt\n",
    "\n",
    "nuskybgd mkinstrmap nu10601407002B01_cl.evt\n",
    "```\n",
    "4. Make the aspect histograms\n",
    "\n",
    "```\n",
    "nuskybgd aspecthist nu10601407002A_det1.fits gtifile=nu10601407002A01_gti.fits \\\n",
    "    out=aspecthistA.fits\n",
    "\n",
    "nuskybgd aspecthist nu10601407002B_det1.fits gtifile=nu10601407002B01_gti.fits \\\n",
    "    out=aspecthistB.fits\n",
    "```\n",
    "\n",
    "5. Go to event_cl/bgd\n",
    "6. Generate the background aperture images. Change the refimg parameter if you called the image file something different.\n",
    "\n",
    "```\n",
    "nuskybgd projbgd refimg=../nu10601407002A01_cl_3to20keV.fits out=bgdapA.fits \\\n",
    "\tmod=A det=1234 chipmap=../newinstrmapA.fits aspect=../aspecthistA.fits\n",
    "\n",
    "nuskybgd projbgd refimg=../nu10601407002A01_cl_3to20keV.fits out=bgdapB.fits \\\n",
    "\tmod=B det=1234 chipmap=../newinstrmapB.fits aspect=../aspecthistB.fits\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f07d56-d30a-4407-9ef6-576be155d1f8",
   "metadata": {},
   "source": [
    "# Go to the bgd directory and produce an input json file. Call it something like bgdinfo.json.\n",
    "\n",
    "It should look something like this, where you're going to use the various inputs. Note that I've found that we're typically better off just fitting the two telescopes independently first and *then* combining in a final ```XSPEC``` run. \n",
    "\n",
    "### Important values to set:\n",
    "\n",
    "-     \"intbgd_fix_line_ratios\": true\n",
    "\n",
    "This is important for tying together all of the internal line components. For *most* part this is what you actually want to do. This is especially true if you have observations <100-ks where the individual background lines are going to be poorly constrained.\n",
    "\n",
    "- fcxb_config\n",
    "\n",
    "This line ties together the focused CXB component. This is somewhat esoteric, but you want the focused CXB to be the same *at the different locations in the FoV* not **for the same detector**. In practice, I think we will typically keep this fixed.\n",
    "\n",
    "- Make sure that the regfiles and bgfiles line up\n",
    "\n",
    "This is an obvious point, but this tells nuskybgd which version to use.\n",
    "\n",
    "\n",
    "---\n",
    "```\n",
    "{\n",
    "    \"bgfiles\": [\n",
    "         \"nu10601407002A01_bgd0A_sr.pha\",\n",
    "         \"nu10601407002A01_bgd1A_sr.pha\",\n",
    "         \"nu10601407002A01_bgd3A_sr.pha\"\n",
    "    ],\n",
    "\n",
    "    \"regfiles\": [\n",
    "        \"bgd0A.reg\",\n",
    "        \"bgd1A.reg\",\n",
    "        \"bgd3A.reg\"\n",
    "    ],\n",
    "\n",
    "    \"refimgf\": \"bgdapA.fits\",\n",
    "\n",
    "    \"bgdapfiles\": {\n",
    "        \"A\": \"bgdapA.fits\",\n",
    "    },\n",
    "    \"bgddetfiles\": {\n",
    "        \"A\": [\n",
    "            \"det0Aim.fits\",\n",
    "            \"det1Aim.fits\",\n",
    "            \"det2Aim.fits\",\n",
    "            \"det3Aim.fits\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"intbgd_fix_line_ratios\": true\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ee3ed-717f-4e25-ac50-72b30613b1c2",
   "metadata": {},
   "source": [
    "# Set up .xcm file for fitting like this:\n",
    "\n",
    "```\n",
    "nuskybgd fit fpma.json savefile=n132d_2020_fpma >& fita.log\n",
    "```\n",
    "\n",
    "## Some notes\n",
    "\n",
    "- This will produce a .xcm file called n132d_2020_fpma.xcm, which will be *starting* point for Xspec fitting of the background.\n",
    "- If you change the json and rerun it again with teh same ```savefile=``` parameter then it will silently append a numeric before the .xcm extension. So just beware that you are using the correct file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b4227-ecf4-49d0-a796-318442203b59",
   "metadata": {},
   "source": [
    "# Start of Xspec Fitting\n",
    "\n",
    "## Start a wrapper .xcm file to use.\n",
    "- Note that you will probably *not* run this via @script.xcm but just copy and paste things as you go into the ```Xspec>``` prompt\n",
    "\n",
    "### Rescale the internal norms correctly\n",
    "\n",
    "```\n",
    "@n132d_2020_fpma.xcm\n",
    "cpd /xw\n",
    "pl ld rat\n",
    "\n",
    "# Rescale intn norms\n",
    "newpar intn:4 1e-4\n",
    "statistic cstat\n",
    "```\n",
    "\n",
    "- ...for some reason the internal background continuum is off by 1e4. Not sure what's wrong in the model, but this is never correct. I always scale it to 1e-4.\n",
    "\n",
    "- Use cstat. If you want to, you can use the ftgrouppha to \"optimally\" bin the data first. At this stage I don't think it makes a ton of difference. Because this is a phenomenological model you don't expect to *ever* get a fit statistic comparable to the degrees of freedom. But if it makes you feel better, defintely go for it.\n",
    "\n",
    "\n",
    "\n",
    "### Turn off the \"solar\" apec component and associated lines\n",
    "\n",
    "\n",
    "```\n",
    "newpar intbgd:4 0. -0.1\n",
    "newpar intbgd:10 0. -0.1\n",
    "newpar intbgd:7 0. -0.1\n",
    "newpar intbgd:13 0. -0.1\n",
    "\n",
    "```\n",
    "\n",
    "- ...all of these \"background\" spectral components were introduced because the COSMOS background fields occured when there were lots of solar flares. These are *not* generally required and we generally recommend filtering these out by hand using GTIs first rather than trying to fit them. They have a different spatial distribution than all of the other background components. If you want to check for the presence of solar activity, see **(some jupyter notebook I haven't written yet)**.\n",
    "\n",
    "- Note that unfortunately the code does not allow you to simply remove these model components, so we just zero them out and freeze them.\n",
    "\n",
    "### Freeze the focused CXB\n",
    "\n",
    "```\n",
    "freeze fcxb:*\n",
    "```\n",
    "\n",
    "- ...this has to be there, but is usually difficult to constrain. Keep it fixed unless you have a good reason to allow it to vary.\n",
    "\n",
    "### Check the \"default\" fit\n",
    "\n",
    "It should looke something like this:\n",
    "\n",
    "![](xspec_default.png)\n",
    "\n",
    "\n",
    "\n",
    "### Do a preliminary fit and check the results\n",
    "\n",
    "```\n",
    "fit 1000\n",
    "pl ld rat\n",
    "\n",
    "```\n",
    "\n",
    "...which should now have fit the continuum and CXB values:\n",
    "\n",
    "![](xspec_preliminary.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c172199-b0f5-4b08-9690-36bad8652f97",
   "metadata": {},
   "source": [
    "## Make adjustments to the fit\n",
    "\n",
    "In this case, the 88 keV line and the 24 keV line are different than the default values with resepect to the other lines. The 24 keV line we know appears after the SAA and the 88 keV line varies with time. You can go thaw these components in the background model as necessary.\n",
    "\n",
    "Here it's important to note that the strength of some of these backgroud components varies *per detector* in ways that are not captured by the ```nuskybgd``` model. Which is why you're generally better off fitting on a \"per detector\" basis.\n",
    "\n",
    "Once you're happy, save your fit in something like this:\n",
    "\n",
    "```\n",
    "save all n132d_2020_fpma_fit.xcm\n",
    "```\n",
    "\n",
    "## Produce the \"simultaneous\" .xcm file\n",
    "\n",
    "```\n",
    "nuskybgd spec fpma.json n132d_2020_fpma_fit.xcm srcA.reg nu10601407002A01_srcA_sr.pha\n",
    "```\n",
    "\n",
    "- Note: there is syntax for doing both FPMs at the same time, but I think you're typically going to be better off doing this epoch-by-epoch and FPM -by-FPM.\n",
    "\n",
    "- This produces a .xcm file usually bgdA.xcm or bgdB.xcm. If you run things again, then it will make something like bgdA2.xcm. This file is echoed to the command line, so keep that in mind when you run this.\n",
    "\n",
    "## Check the projection\n",
    "\n",
    "bgdA.xcm now has the background and source spectrum all loaded in. In principle, you can use this data and simultaneously fit both the background model in both the source *and* background regions (which is statistically correct). However, this tends to be computationally expensive and does not allow for any variations in the underlying spatial model (or relative strength between detectors).\n",
    "\n",
    "In my case, it looks like this, where I have combined the two background regions (the black curve) and am showing the source counts spectrum.\n",
    "\n",
    "\n",
    "![](xspec_source_and_bgd.png)\n",
    "\n",
    "\n",
    "\n",
    "## Finally, \"simplify\" the xcm file\n",
    "\n",
    "If you want to just retain a (fixed) background model projected into your source region, you can use the following syntax:\n",
    "\n",
    "```\n",
    "nuskybgd simplify fpma.json bgd_srcA.xcm\n",
    "\n",
    "```\n",
    "...which produces \"bgd_only_srcA.xcm\", which is *actually* just the source spectrum with its background model. When you load this is to Xspec via @bgd_only_srcA.xcm you \n",
    "\n",
    "...so that when you load the bdg_srcA.xcm file it now contains *only* the projected background spectrum. You can still add a source model using the\n",
    "\n",
    "```\n",
    "model powerlaw\n",
    "```\n",
    "\n",
    "...or whatever since \"model 1\" is reserved by ```nuskybgd``` for the actual source model.\n",
    "\n",
    "At this point it's also possible to merge things together (by hand) so that you can fit multiple epochs and/or both FPMs. **We can give an example here?** This is not too complicated to do by hand for a limited number of observations, and could be semi-automated in the future. If you do this, then it is *not* recommend to try to simultaneously fit the background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dca38a-e345-424b-9742-a098c08cea2f",
   "metadata": {},
   "source": [
    "# Final notes\n",
    "\n",
    "- It's left up to the user to figure out what to do next as far as using the \"correct\" fit energy range and models. I'd typically recommend here using ftgrouppha and limiting yourself to only fitting up until the background starts to become dominant. Otherwise you're just including the extra degrees of freedom from the background fit, which will not be correct.\n",
    "\n",
    "- It's definitely not clear that any fit statistics will be chi-square distributed. So do your own dilligence to make sure you understand goodness of fit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
